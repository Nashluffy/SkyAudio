{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras - Learning the Basic\n",
    "The purpose of this module is to teach myself the basic understanding of TensorFlow. Using Keras, a high-level API, to buld and train deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "print(\"tf.keras version: \" + tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Neural network research is motivated by two desired. \n",
    "1. To obtain a better understanding of the human brain\n",
    "2. To develop computers that can deal with abstract problems.\n",
    "\n",
    "Ex: A computer has a hard time recognizing people's faces.\n",
    "\n",
    "You can think of a neural network as a complex math function that makes predictions. **Training** is the process of finding values for the network weights and bias constants that define the behavior of the network.\n",
    "\n",
    "A neural network is composed of three different layers:\n",
    "1. Input layer\n",
    "2. hidden layer\n",
    "3. output layer\n",
    "Each layer consist of one or more nodes.\n",
    "\n",
    "Below is a image of common used neural network structure.\n",
    "\n",
    "<img src = \"http://www.dspguide.com/graphics/F_26_5.gif\">\n",
    "\n",
    "The small circles represent the nodes.\n",
    "The lines between the nodes indicate the flow of information.\n",
    "\n",
    "For more information visit [here](http://www.dspguide.com/ch26/2.htm)\n",
    "Or read this book [Deep learning with Python](https://github.com/hktxt/bookshelf/blob/master/Computer%20Science/Deep%20Learning%20with%20Python%2C%20Fran%C3%A7ois%20Chollet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras you assemble layers to build models. \n",
    "\n",
    "**Models are typically a graph of layers**\n",
    "\n",
    "Lets build a simple, fully-connected network (multi-layer perceptron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "#building common type of model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "#Adding a densely-connected layer with 64 units to the model\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#add another\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "#Finish off with a softmax layer with 10 output units\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_So you may be wondering what does some of this stuff mean. So lets break it down._\n",
    "\n",
    "* A densely connected layer is a linear operation in whcih every input is connected to every output by a weight. \n",
    "\n",
    "* The 64 represents the dimensionality of the output space.(output shape)\n",
    "\n",
    "* Activation represents the activation function to use for that layer. (relu - rectifier) \n",
    "\n",
    "* Softmax layers are implemented right before the output layer and must contain the same number of nodes as the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7efeb7bb6b70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a sigmoid layer:\n",
    "layers.Dense(64, activation ='sigmoid')\n",
    "\n",
    "#Or you could create it this way\n",
    "layers.Dense(64, activation=tf.sigmoid)\n",
    "\n",
    "#A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:\n",
    "layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "\n",
    "#A linear layer with L2 regularization of factor 0.01 applied to the bias vector:\n",
    "layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "#A linear layer with a kernel initialized to a random orthogonal matrix:\n",
    "layers.Dense(64, kernel_initializer='orthogonal')\n",
    "\n",
    "#A linear layer with a bias vector initialized to 2.0s:\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The block of code above indicates the configuration of the layers_\n",
    "\n",
    "* As mentioned earlier the activation sets the activation for that specific layer. \n",
    "\n",
    "* **kernel_initializer** and **bias_initializer** indicates the initialization schemes that creates the layers weight.\n",
    "\n",
    "* **kernel_regularizer** and **bias_regularizer** indicates the regularization schemes that apply the layers weight.\n",
    "\n",
    "*  **_Regulatization_** is a technique used to reduce the likelihood of neural network model overfitting. \n",
    "\n",
    "* **Model overfitting** occurs when you train a neural network for too many iterations. This can lead to the neural network model predicting the output values for the **training data** very well. However, when that model is applied to *new and unseen data* the model predicts poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leedagr8/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Train and evaluate your model\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "#add a densely connected layer with 64 units\n",
    "    layers.Dense(64, activation ='relu', input_shape=(32,)),\n",
    "#add another\n",
    "    layers.Dense(64, activation ='relu'),\n",
    "#Add a softmax layer with 10 output units\n",
    "    layers.Dense(10, activation='softmax')])\n",
    "\n",
    "#call the compile method to configure its learning process\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Since we have successfully constructed a model we can finally set up our training process. This is done by the **compile** method_\n",
    "\n",
    "**tf.keras.Model.compile** takes 3 arguments:\n",
    "* Optimizer: object that specifies the training procedure. \n",
    "    * optimizer instances from **tf.train module**: tf.train.AdamOptimizer, tf.train.RMSPropOptmizer, or tf.train.GradientDescentOptimizer\n",
    "* loss: The function to minimize during optimization. These functions are specified by name or by passing a callable object from the **tf.keras.losses module**\n",
    "    * mean square error(mse)\n",
    "    * categorical_crossentropy,\n",
    "    * binary_crossentropy\n",
    "* metrics: Used to monitor training. Can be either string names or callabes from **tf.keras.metrics**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leedagr8/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "             loss='mse',        #mean squared error\n",
    "             metrics=['mae'])   # mean absolute error\n",
    "\n",
    "#configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small datasets, use in-memory NumPy arrays to train and evaluate a model. The model is \"fit\" to the training data using the fit method.\n",
    "\n",
    "**NumPy**: the fundamental package for scientific computing with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leedagr8/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 11.6279 - categorical_accuracy: 0.1050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.5109 - categorical_accuracy: 0.1040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 11.4994 - categorical_accuracy: 0.1130\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.4915 - categorical_accuracy: 0.1130\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 11.4894 - categorical_accuracy: 0.1080\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.4885 - categorical_accuracy: 0.1150\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 11.4895 - categorical_accuracy: 0.1090\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 11.4899 - categorical_accuracy: 0.1170\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 11.4854 - categorical_accuracy: 0.1030\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 11.4830 - categorical_accuracy: 0.1470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efeb6eef710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_tf.keras.Model.fit_ takes 3 arguments\n",
    "\n",
    "* epochs: one iteration over the entire input data\n",
    "\n",
    "* batch_size: The model slices the data into smaller batches and iterates over these batches during training. This integer specifies the size of each batch,\n",
    "    * **Note: The last batch may be smaller if the total number of samples is not divisble by the batch size.**\n",
    "\n",
    "* validation_data: Allows the model to display the loss and metrics in inference mode for the pass data. IS used to easily monitor its performance on some validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 11.5195 - categorical_accuracy: 0.1020 - val_loss: 11.7923 - val_categorical_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 11.5162 - categorical_accuracy: 0.1080 - val_loss: 11.7889 - val_categorical_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 55us/sample - loss: 11.5181 - categorical_accuracy: 0.1030 - val_loss: 11.7928 - val_categorical_accuracy: 0.0900\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 54us/sample - loss: 11.5182 - categorical_accuracy: 0.0810 - val_loss: 11.7943 - val_categorical_accuracy: 0.0700\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 11.5167 - categorical_accuracy: 0.1050 - val_loss: 11.7906 - val_categorical_accuracy: 0.0900\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 11.5160 - categorical_accuracy: 0.1120 - val_loss: 11.8012 - val_categorical_accuracy: 0.0700\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 11.5138 - categorical_accuracy: 0.1150 - val_loss: 11.7840 - val_categorical_accuracy: 0.1400\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 11.5126 - categorical_accuracy: 0.1090 - val_loss: 11.7968 - val_categorical_accuracy: 0.1900\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 11.5080 - categorical_accuracy: 0.1240 - val_loss: 11.7966 - val_categorical_accuracy: 0.1000\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 11.5073 - categorical_accuracy: 0.1210 - val_loss: 11.8030 - val_categorical_accuracy: 0.1700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efeb6eef470>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an example of using validation_data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "val_data = np.random.random((100, 32))\n",
    "val_labels = np.random.random((100, 10))\n",
    "\n",
    "model.fit(data, labels, epochs=10, batch_size=32,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 11.4851 - categorical_accuracy: 0.1146\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5275 - categorical_accuracy: 0.1165\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5081 - categorical_accuracy: 0.1250\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5260 - categorical_accuracy: 0.1442\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4505 - categorical_accuracy: 0.1474\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4792 - categorical_accuracy: 0.1346\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4909 - categorical_accuracy: 0.1464\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5144 - categorical_accuracy: 0.1560\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4971 - categorical_accuracy: 0.1560\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.5163 - categorical_accuracy: 0.1656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efeb4326390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input tf.data datasets\n",
    "#Use the Datasets API to scale to large datasets or multi-device\n",
    "#training.\n",
    "\n",
    "# Instantiates a toy dataset instance:\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "# Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit method uses the **steps_per_epoch** argument. This argument is the number of training steps the model runs before it moves to the next epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 11.4525 - categorical_accuracy: 0.1656 - val_loss: 11.8525 - val_categorical_accuracy: 0.0625\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4914 - categorical_accuracy: 0.1613 - val_loss: 11.5858 - val_categorical_accuracy: 0.0882\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - loss: 11.4736 - categorical_accuracy: 0.1645 - val_loss: 11.7286 - val_categorical_accuracy: 0.0588\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4877 - categorical_accuracy: 0.1848 - val_loss: 11.3357 - val_categorical_accuracy: 0.1176\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4202 - categorical_accuracy: 0.1784 - val_loss: 11.8741 - val_categorical_accuracy: 0.1146\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4477 - categorical_accuracy: 0.1624 - val_loss: 11.6043 - val_categorical_accuracy: 0.1176\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4564 - categorical_accuracy: 0.1891 - val_loss: 11.7411 - val_categorical_accuracy: 0.0735\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4827 - categorical_accuracy: 0.1838 - val_loss: 11.3435 - val_categorical_accuracy: 0.1765\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4646 - categorical_accuracy: 0.1635 - val_loss: 11.8962 - val_categorical_accuracy: 0.1042\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 11.4845 - categorical_accuracy: 0.1795 - val_loss: 11.6396 - val_categorical_accuracy: 0.1176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efeb42fe358>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(32).repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))\n",
    "val_dataset = val_dataset.batch(32).repeat()\n",
    "\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset,\n",
    "          validation_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 105us/sample - loss: 11.6654 - categorical_accuracy: 0.1030\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 11.4799 - categorical_accuracy: 0.1698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.479937775929768, 0.16979167]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now evaluate and predict\n",
    "\n",
    "#using the tf.keras.Model.evaluate and tf.keras.Model.predict methods\n",
    "# we can evaluate the inference-mode loss and metrics for the data provied.\n",
    "\n",
    "data = np.random.random((1000, 32))\n",
    "labels = np.random.random((1000, 10))\n",
    "\n",
    "model.evaluate(data, labels, batch_size=32)\n",
    "\n",
    "model.evaluate(dataset, steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# To predict the output of the last layer in inference for the\n",
    "# data provided, as a NumPy array\n",
    "\n",
    "result = model.predict(data, batch_size=32)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
